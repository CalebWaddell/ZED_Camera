///////////////////////////////////////////////////////////////////////////
//
// Copyright (c) 2017, STEREOLABS.
//
// All rights reserved.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
///////////////////////////////////////////////////////////////////////////


/***************************************************************************************************
 ** This sample demonstrates how to grab images and depth/disparity map with the ZED SDK          **
 ** Both images and depth/disparity map are displayed with OpenCV                                 **
 ** Most of the functions of the ZED SDK are linked with a key press event (using OpenCV)         **
 ***************************************************************************************************/

#include <sl/Camera.hpp>
#include <opencv2/opencv.hpp>
#include <sl/Core.hpp>
#include <sl/defines.hpp>

using namespace sl;
using namespace cv;

cv::Mat slMat2cvMat(sl::Mat& input);
void detectObjects(cv::Mat* thresh_img, cv::Mat* orig_img, cv::Scalar color);


int main(int argc, char **argv) {

    // Create a ZED camera object
    Camera zed;

    // Set configuration parameters
    InitParameters init_params;
    init_params.camera_resolution = RESOLUTION_HD720;
    init_params.depth_mode = DEPTH_MODE_PERFORMANCE;
    init_params.coordinate_units = sl::UNIT_METER;

    // Open the camera
    ERROR_CODE err = zed.open(init_params);
    if (err != SUCCESS)
        return 1;

    // Set runtime parameters after opening the camera
    RuntimeParameters runtime_parameters;
    runtime_parameters.sensing_mode = SENSING_MODE_STANDARD; // Use STANDARD sensing mode

    // Create sl and cv Mat to get ZED left image and depth image
    // Best way of sharing sl::Mat and cv::Mat :
    // Create a sl::Mat and then construct a cv::Mat using the ptr to sl::Mat data.
    Resolution image_size = zed.getResolution();
	sl::Mat image_zed(image_size, sl::MAT_TYPE_8U_C4); // Create a sl::Mat to handle Left image
	cv::Mat image_ocv = slMat2cvMat(image_zed);
	sl::Mat depth_image_zed(image_size, MAT_TYPE_8U_C4);
	cv::Mat depth_image_ocv = slMat2cvMat(depth_image_zed);

	sl::Mat depthImageRaw_zed(image_size, sl::MAT_TYPE_32F_C1); // Create a sl::Mat to handle depth image (32 bit floats)
	cv::Mat depthImageRaw_ocv = slMat2cvMat(depthImageRaw_zed);

	cv::Mat depthImageThresh, depthImageThreshCLOSE, depthImageThreshMEDIUM,depthImageThreshFAR;
	depthImageThresh = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	depthImageThreshCLOSE = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	depthImageThreshMEDIUM = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	depthImageThreshFAR = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);


	cv::Mat depthImageThreshThreeChannels;
	depthImageThreshThreeChannels = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC3);
	cv::Mat threshMatArray[3];
	threshMatArray[0] = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	threshMatArray[1] = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	threshMatArray[2] = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);

	cv::Mat depthImageThreshTOOFAR,depthImageThreshTOOCLOSE,depthImageThreshNAN;
	cv::Mat NANMask,negInfMask,posInfMask,closeMask,testMask;
	negInfMask = cv::Mat::zeros(image_size.height,image_size.width,CV_32FC1);
	posInfMask = cv::Mat::zeros(image_size.height,image_size.width,CV_32FC1);
	closeMask = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);
	testMask = cv::Mat::zeros(image_size.height,image_size.width,CV_8UC1);

    // Create OpenCV images to display (lower resolution to fit the screen)
    cv::Size displaySize(480, 269);
    cv::Mat image_ocv_display(displaySize, CV_8UC4);
    cv::Mat depth_image_ocv_display(displaySize, CV_8UC4);

    // Give a name to OpenCV Windows
    cv::namedWindow("Image", cv::WINDOW_AUTOSIZE);
    //cv::namedWindow("Depth", cv::WINDOW_AUTOSIZE);

    // Jetson only. Execute the calling thread on 2nd core
    Camera::sticktoCPUCore(2);

    // Loop until 'q' is pressed
    char key = ' ';

    int64_t lastTick = getTickCount();
    int64_t currentTick = getTickCount();
    double tickFreq = getTickFrequency();
    double fps = 0;

    while (key != 'q') {

    	lastTick = getTickCount();

        // Grab and display image and depth
        if (zed.grab(runtime_parameters) == SUCCESS) {

            zed.retrieveImage(image_zed, VIEW_LEFT); // Retrieve the left image
            zed.retrieveImage(depth_image_zed, VIEW_DEPTH); //Retrieve the depth view (image)
            zed.retrieveMeasure(depthImageRaw_zed, MEASURE_DEPTH); // Retrieve the depth measure (32bits)

            //NANMask = cv::Mat(depthImageRaw_ocv != depthImageRaw_ocv);
            //threshold(depthImageRaw_ocv,negInfMask,0,255,THRESH_BINARY_INV);	//anything less than 0
            //negInfMask.convertTo(negInfMask,CV_8UC1);

            //threshold(depthImageRaw_ocv,posInfMask,30.0,255,THRESH_BINARY);	//anything greater than 30
            //posInfMask.convertTo(posInfMask,CV_8UC1);
            //mshow("Neg Inf", negInfMask);
            //imshow("Pos Inf", posInfMask);


            inRange(depthImageRaw_ocv,Scalar(1.0),Scalar(2.0),closeMask);	//0-2m
            imshow("raw", depthImageRaw_ocv);
            imshow("mask", closeMask);

            //threshold(depthImageRaw_ocv,depthImageThresh,2.0,255,THRESH_BINARY_INV);
            //threshold(depthImageRaw_ocv,depthImageThreshTOOFAR,30.0,255,THRESH_BINARY);
            //threshold(depthImageRaw_ocv,depthImageThreshTOOCLOSE,0.01,255,THRESH_BINARY_INV);
            //imshow("Thresh", depthImageThresh);
            for (int y = 0; y < image_size.height-1; y++){
            	for (int x = 0; x < image_size.width-1; x++){

            		sl::float1 dist;
            		depthImageRaw_zed.getValue(x, y, &dist);
            		Vec3b * pixelPointer = depthImageThreshThreeChannels.ptr<Vec3b>(y,x);
            		if(isValidMeasure(dist)){
            			if(dist < 1){

            				sl::float1 testVal = depthImageRaw_ocv.at<float>(y,x);

            				depthImageThresh.at<uchar>(y,x) = 255;
//            				depthImageThreshCLOSE.at<uchar>(y,x) = 255;
//            				depthImageThreshMEDIUM.at<uchar>(y,x) = 0;
//            				depthImageThreshFAR.at<uchar>(y,x) = 0;
            				//depthImageThreshThreeChannels.at<Vec3b>(y,x) = Vec3b(255,0,0);
            				*pixelPointer = Vec3b(255,0,0);
            			}
            			else if(dist < 2){
							depthImageThresh.at<uchar>(y,x) = 180;
//							depthImageThreshCLOSE.at<uchar>(y,x) = 0;
//							depthImageThreshMEDIUM.at<uchar>(y,x) = 255;
//							depthImageThreshFAR.at<uchar>(y,x) = 0;
							//depthImageThreshThreeChannels.at<Vec3b>(y,x) = Vec3b(0,255,0);
							*pixelPointer = Vec3b(0,255,0);
						}
            			else if(dist < 3){
							depthImageThresh.at<uchar>(y,x) = 120;
//							depthImageThreshCLOSE.at<uchar>(y,x) = 0;
//							depthImageThreshMEDIUM.at<uchar>(y,x) = 0;
//							depthImageThreshFAR.at<uchar>(y,x) = 255;
							//depthImageThreshThreeChannels.at<Vec3b>(y,x) = Vec3b(0,0,255);
							*pixelPointer = Vec3b(0,0,255);
						}
            			else{
            				depthImageThresh.at<uchar>(y,x) = 0;
//            				depthImageThreshCLOSE.at<uchar>(y,x) = 0;
//            				depthImageThreshMEDIUM.at<uchar>(y,x) = 0;
//            				depthImageThreshFAR.at<uchar>(y,x) = 0;
            				//depthImageThreshThreeChannels.at<Vec3b>(y,x) = Vec3b(0,0,0);
            				*pixelPointer = Vec3b(0,0,0);
            			}
            		}
            		else{
            			depthImageThresh.at<uchar>(y,x) = 0;
//            			depthImageThreshCLOSE.at<uchar>(y,x) = 0;
//            			depthImageThreshMEDIUM.at<uchar>(y,x) = 0;
//            			depthImageThreshFAR.at<uchar>(y,x) = 0;
            			//depthImageThreshThreeChannels.at<Vec3b>(y,x) = Vec3b(0,0,0);
            			*pixelPointer = Vec3b(0,0,0);
            		}
            	}
            }
            //imshow("Thresh Too Close", depthImageThreshTOOFAR);
            //imshow("Thresh Too Far", depthImageThreshTOOCLOSE);

            //imshow("Thresh CLOSE", depthImageThreshCLOSE);

            cv::split(depthImageThreshThreeChannels,threshMatArray);

            detectObjects(&threshMatArray[0],&image_ocv,Scalar(0,0,255));
            detectObjects(&threshMatArray[1],&image_ocv,Scalar(0,106,255));
            detectObjects(&threshMatArray[2],&image_ocv,Scalar(0,255,0));

//            detectObjects(&depthImageThreshCLOSE,&image_ocv,Scalar(0,0,255));
//			detectObjects(&depthImageThreshMEDIUM,&image_ocv,Scalar(0,106,255));
//			detectObjects(&depthImageThreshFAR,&image_ocv,Scalar(0,255,0));

            imshow("Thresh", depthImageThresh);


            // Resize and display with OpenCV
            cv::resize(image_ocv, image_ocv_display, displaySize);
            imshow("Image", image_ocv_display);
            //cv::resize(depth_image_ocv, depth_image_ocv_display, displaySize);
            //imshow("Depth", depth_image_ocv_display);

            key = cv::waitKey(1);

            currentTick = getTickCount();
            fps =1/((currentTick-lastTick)/tickFreq);
            printf("FPS: %f\n",fps);
            ;
        }
    }

    zed.close();
    return 0;
}

cv::Mat slMat2cvMat(sl::Mat& input)
{

	//convert MAT_TYPE to CV_TYPE
	int cv_type = -1;
	switch (input.getDataType())
	{
	case sl::MAT_TYPE_32F_C1: cv_type = CV_32FC1; break;
	case sl::MAT_TYPE_32F_C2: cv_type = CV_32FC2; break;
	case sl::MAT_TYPE_32F_C3: cv_type = CV_32FC3; break;
	case sl::MAT_TYPE_32F_C4: cv_type = CV_32FC4; break;
	case sl::MAT_TYPE_8U_C1: cv_type = CV_8UC1; break;
	case sl::MAT_TYPE_8U_C2: cv_type = CV_8UC2; break;
	case sl::MAT_TYPE_8U_C3: cv_type = CV_8UC3; break;
	case sl::MAT_TYPE_8U_C4: cv_type = CV_8UC4; break;
	default: break;
	}

	// cv::Mat data requires a uchar* pointer. Therefore, we get the uchar1 pointer from sl::Mat (getPtr<T>())
	//cv::Mat and sl::Mat will share the same memory pointer
	return cv::Mat(input.getHeight(), input.getWidth(), cv_type, input.getPtr<sl::uchar1>(MEM_CPU));
}

void detectObjects(cv::Mat* thresh_img, cv::Mat* orig_img, cv::Scalar color) {
	vector<vector<Point> > contours;
	vector<Vec4i> hierarchy;
	cv::findContours(*thresh_img, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, cv::Point(0, 0));
	vector<Moments> mu(contours.size());
	for (int i = 0; i < contours.size(); i++) {
		mu[i] = moments(contours[i], false);
	}
	vector<Point2f> mc(contours.size());
	for (int i = 0; i < contours.size(); i++) {
		mc[i] = Point2f(mu[i].m10 / mu[i].m00, mu[i].m01 / mu[i].m00);
	}

	int area = 0;
	int perimeter = 0;
	float circularity = 1;
	std::cout << "size: " << contours.size() << std::endl;
	for (int i = 0; i < contours.size(); i++)
	{
		area = contourArea(contours[i]);
		perimeter = arcLength(contours[i], true);
		circularity = (((float)perimeter*(float)perimeter) / (4 * CV_PI*(float)area));

		if ((area > 5000)){//&&(area < thresh_high)) {
			drawContours(*orig_img, contours, i, color, 5, 8, hierarchy, 0, Point());
			if(color == Scalar(0,0,255)){
				cv::circle(*orig_img, mc[i], 50, color, 3, 8, 0);
				std::cout << "Critical Object Detected @ " << mc[i] << std::endl;
			}
		}
	}
}
//static void onMouseCallback(int32_t event, int32_t x, int32_t y, int32_t flag, void * param) {
//    if (event == CV_EVENT_LBUTTONDOWN) {
//        mouseOCVStruct* data = (mouseOCVStruct*) param;
//        int y_int = (y * data->depth.getHeight() / data->_resize.height);
//        int x_int = (x * data->depth.getWidth() / data->_resize.width);
//
//        sl::float1 dist;
//        data->depth.getValue(x_int, y_int, &dist);
//
//        std::cout << std::endl;
//        if (isValidMeasure(dist))
//            std::cout << "Depth at (" << x_int << "," << y_int << ") : " << dist << "m";
//        else {
//            std::string depth_status;
//            if (dist == TOO_FAR) depth_status = ("Depth is too far.");
//            else if (dist == TOO_CLOSE) depth_status = ("Depth is too close.");
//            else depth_status = ("Depth not available");
//            std::cout << depth_status;
//        }
//        std::cout << std::endl;
//    }
//}
